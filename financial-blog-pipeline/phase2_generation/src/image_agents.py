#!/usr/bin/env python3
"""
Specialized agents for image generation workflow
"""

import os
import json
import requests
from typing import Dict, List, Optional
import openai
import anthropic
from dotenv import load_dotenv

load_dotenv()

class ImageContextAnalyzerAgent:
    """Agent responsible for analyzing blog content and extracting image contexts"""
    
    def __init__(self):
        self.anthropic_client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY')) if os.getenv('ANTHROPIC_API_KEY') else None
    
    def analyze_content(self, content: str, title: str) -> Dict:
        """Analyze blog content and extract image contexts"""
        if not self.anthropic_client:
            print("âŒ Anthropic API key not available for context analysis.")
            return {"contexts": [], "strategy": "fallback"}
        
        analysis_prompt = f"""
        åˆ†æä»¥ä¸‹è²¡ç¶“éƒ¨è½æ ¼æ–‡ç« å…§å®¹ï¼Œä¸¦æ±ºå®šéœ€è¦å“ªäº›åœ–ç‰‡ä¾†å¢å¼·æ–‡ç« æ•ˆæœã€‚
        
        æ–‡ç« æ¨™é¡Œï¼š{title}
        
        æ–‡ç« å…§å®¹ï¼š
        {content}
        
        è«‹åˆ†ææ–‡ç« å…§å®¹ä¸¦æä¾›ï¼š
        1. æ–‡ç« ä¸­æåˆ°çš„å…·é«”å…¬å¸ã€è‚¡ç¥¨æˆ–é‡‘èç”¢å“
        2. æ–‡ç« è¨è«–çš„ä¸»è¦å¸‚å ´æˆ–æŒ‡æ•¸
        3. æ–‡ç« çš„æ ¸å¿ƒä¸»é¡Œå’Œæƒ…æ„Ÿï¼ˆæ¨‚è§€ã€æ‚²è§€ã€ä¸­æ€§ç­‰ï¼‰
        4. å»ºè­°çš„åœ–ç‰‡é¡å‹ï¼ˆåœ–è¡¨ã€ç…§ç‰‡ã€æ’åœ–ç­‰ï¼‰
        5. å…·é«”çš„åœ–ç‰‡æœç´¢é—œéµè©ï¼ˆç¹é«”ä¸­æ–‡ï¼‰
        6. åœ–ç‰‡åœ¨æ–‡ç« ä¸­çš„ä½ç½®å»ºè­°
        
        å›ç­”æ ¼å¼å¦‚ä¸‹ï¼š
        å…¬å¸èˆ‡è‚¡ç¥¨ï¼š[åˆ—å‡ºæ‰€æœ‰æåˆ°çš„å…¬å¸å’Œè‚¡ç¥¨ä»£ç¢¼]
        å¸‚å ´æŒ‡æ•¸ï¼š[åˆ—å‡ºç›¸é—œå¸‚å ´æŒ‡æ•¸]
        æ ¸å¿ƒä¸»é¡Œï¼š[æè¿°æ–‡ç« ä¸»è¦è¨è«–çš„ä¸»é¡Œ]
        æƒ…æ„Ÿå‚¾å‘ï¼š[æ¨‚è§€/æ‚²è§€/ä¸­æ€§]
        åœ–ç‰‡å»ºè­°ï¼š[å»ºè­°çš„åœ–ç‰‡é¡å‹å’Œæœç´¢é—œéµè©]
        ä½ç½®å»ºè­°ï¼š[åœ–ç‰‡åœ¨æ–‡ç« ä¸­çš„ä½ç½®]
        """
        
        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=500,
                messages=[{"role": "user", "content": analysis_prompt}]
            )
            
            analysis = response.content[0].text
            
            # Parse the analysis into structured data
            contexts = self._parse_analysis(analysis)
            
            return {
                "contexts": contexts,
                "strategy": "llm_guided" if contexts else "fallback"
            }
            
        except Exception as e:
            print(f"âŒ Error in content analysis: {e}")
            return {"contexts": [], "strategy": "fallback"}
    
    def _parse_analysis(self, analysis: str) -> List[Dict]:
        """Parse LLM analysis into structured contexts"""
        contexts = []
        lines = analysis.split('\n')
        
        for line in lines:
            if 'åœ–ç‰‡å»ºè­°ï¼š' in line:
                # Extract keywords and image types
                suggestion = line.split('åœ–ç‰‡å»ºè­°ï¼š')[-1]
                # Simple parsing - in practice, you might want more sophisticated parsing
                keywords = [kw.strip() for kw in suggestion.split('ã€') if kw.strip()]
                
                for keyword in keywords[:2]:  # Limit to 2 contexts
                    contexts.append({
                        "keyword": keyword,
                        "type": self._determine_image_type(keyword),
                        "position": "top"  # Default position
                    })
        
        return contexts
    
    def _determine_image_type(self, keyword: str) -> str:
        """Determine image type based on keyword"""
        financial_terms = ['å°è‚¡', 'ç¾è‚¡', 'æ¸¯è‚¡', 'æŒ‡æ•¸', 'åœ–è¡¨', 'èµ°å‹¢', 'Kç·š', 'è‚¡åƒ¹', 'è²¡å ±']
        
        if any(term in keyword for term in financial_terms):
            return "chart"
        elif any(char.isdigit() for char in keyword):
            return "chart"
        else:
            return "photo"

class ImagePromptGeneratorAgent:
    """Agent responsible for generating image prompts based on contexts"""
    
    def __init__(self):
        self.anthropic_client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY')) if os.getenv('ANTHROPIC_API_KEY') else None
    
    def generate_prompts(self, contexts: List[Dict], content: str) -> List[Dict]:
        """Generate image prompts for each context"""
        prompts = []
        
        for context in contexts:
            if context["type"] == "chart":
                prompt = self._generate_chart_prompt(context["keyword"])
            else:
                prompt = self._generate_search_prompt(context["keyword"])
            
            prompts.append({
                "context": context,
                "prompt": prompt,
                "method": "generate" if context["type"] == "chart" else "search"
            })
        
        return prompts
    
    def _generate_chart_prompt(self, keyword: str) -> str:
        """Generate prompt for chart generation"""
        return f"Professional financial chart showing {keyword} performance, clean design, green and red colors, Chinese labels"
    
    def _generate_search_prompt(self, keyword: str) -> str:
        """Generate prompt for image search"""
        return keyword

class ImageGeneratorAgent:
    """Agent responsible for generating images using DALL-E"""
    
    def __init__(self):
        self.openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY')) if os.getenv('OPENAI_API_KEY') else None
    
    def generate_images(self, prompts: List[Dict]) -> List[str]:
        """Generate images using DALL-E"""
        images = []
        
        if not self.openai_client:
            print("âŒ OpenAI API key not available for image generation.")
            return images
        
        for prompt_data in prompts:
            if prompt_data["method"] == "generate":
                try:
                    response = self.openai_client.images.generate(
                        model="dall-e-3",
                        prompt=prompt_data["prompt"],
                        size="1024x1024",
                        quality="standard",
                        n=1
                    )
                    images.append(response.data[0].url)
                except Exception as e:
                    print(f"âŒ Error generating image: {e}")
        
        return images

class ImageSearchAgent:
    """Agent responsible for searching images using Unsplash"""
    
    def __init__(self):
        self.unsplash_api_key = os.getenv('UNSPLASH_API_KEY')
    
    def search_images(self, prompts: List[Dict]) -> List[str]:
        """Search images using Unsplash"""
        images = []
        
        if not self.unsplash_api_key:
            print("âŒ Unsplash API key not available for image search.")
            return images
        
        for prompt_data in prompts:
            if prompt_data["method"] == "search":
                try:
                    url = "https://api.unsplash.com/search/photos"
                    headers = {"Authorization": f"Client-ID {self.unsplash_api_key}"}
                    params = {
                        "query": prompt_data["prompt"],
                        "per_page": 1,
                        "orientation": "landscape"
                    }
                    
                    response = requests.get(url, headers=headers, params=params)
                    response.raise_for_status()
                    
                    data = response.json()
                    if data["results"]:
                        images.append(data["results"][0]["urls"]["regular"])
                except Exception as e:
                    print(f"âŒ Error searching for image: {e}")
        
        return images

class ImageOrchestratorAgent:
    """Orchestrator agent that coordinates all image generation tasks"""
    
    def __init__(self):
        self.context_analyzer = ImageContextAnalyzerAgent()
        self.prompt_generator = ImagePromptGeneratorAgent()
        self.image_generator = ImageGeneratorAgent()
        self.image_searcher = ImageSearchAgent()
    
    def generate_images(self, content: str, title: str) -> List[str]:
        """Main method to orchestrate image generation workflow"""
        # Step 1: Analyze content to extract contexts
        print("ğŸ” Analyzing blog content for image contexts...")
        analysis_result = self.context_analyzer.analyze_content(content, title)
        
        if not analysis_result["contexts"]:
            print("â„¹ï¸  No image contexts found, using fallback method.")
            return self._fallback_generation(content)
        
        # Step 2: Generate prompts based on contexts
        print("ğŸ“ Generating image prompts...")
        prompts = self.prompt_generator.generate_prompts(analysis_result["contexts"], content)
        
        # Step 3: Generate images using appropriate methods
        print("ğŸ–¼ï¸  Generating/searching images...")
        generated_images = self.image_generator.generate_images(prompts)
        searched_images = self.image_searcher.search_images(prompts)
        
        # Combine all images
        all_images = generated_images + searched_images
        
        print(f"âœ… Generated {len(all_images)} images")
        return [img for img in all_images if img]
    
    def _fallback_generation(self, content: str) -> List[str]:
        """Fallback method when LLM analysis fails"""
        # Simple keyword-based approach
        keywords = [
            "å°ç©é›»", "å°è‚¡", "ç¾è‚¡", "æ¸¯è‚¡", "æ’ç”ŸæŒ‡æ•¸", "ç§‘æŠ€è‚¡",
            "é‡‘èè‚¡", "æˆ¿åœ°ç”¢", "åŠ å¯†è²¨å¹£", "AI", "åŠå°é«”"
        ]
        
        found_keywords = [k for k in keywords if k in content]
        images = []
        
        if found_keywords and isinstance(self.image_generator, ImageGeneratorAgent) and self.image_generator.openai_client:
            try:
                response = self.image_generator.openai_client.images.generate(
                    model="dall-e-3",
                    prompt=f"Professional financial chart showing {found_keywords[0]} performance",
                    size="1024x1024",
                    quality="standard",
                    n=1
                )
                images.append(response.data[0].url)
            except Exception as e:
                print(f"âŒ Error in fallback generation: {e}")
        
        return images