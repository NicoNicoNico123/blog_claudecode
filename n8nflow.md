n8n Master/Agent Workflow Concept for YouTube-to-Blog PipelineThis concept outlines a robust, modular automation structure within n8n. It uses a central Master Orchestrator Workflow to manage the overall process and calls multiple, specialized Agent Workflows to perform specific tasks.High-Level ArchitectureThe entire system is composed of one master workflow and several smaller, single-purpose agent workflows.Master Orchestrator Workflow: This is the "brain." It doesn't perform the tasks itself. Its only job is to call the agents in the correct sequence, handle the data flow between them, and manage error handling for the entire pipeline.Agent Workflows: These are the "workers." Each one is an independent workflow responsible for a single part of the process (e.g., fetching a transcript, writing text, generating an image). They are triggered by the Master Orchestrator via a webhook call.Visual Flow:[Master] --(ChannelID)--> [Agent 1: Fetcher]
[Master] <-- (Transcript) -- [Agent 1: Fetcher]

  |
  V

[Master] --(Transcript)--> [Agent 2: Writer]
[Master] <-- (Blog Text) --- [Agent 2: Writer]

  |
  V

[Master] --(Blog Text)--> [Agent 3: Visual Extractor]
[Master] <-- (Image Prompts) -- [Agent 3: Visual Extractor]

  |
  V

...and so on for all phases.
1. The Master Orchestrator WorkflowThis is the main workflow you will run.Trigger: Cron Node (e.g., "Run every day at 9 AM").Core Logic: A linear sequence of Execute Workflow nodes. Each node calls one of the Agent Workflows.State Management: Uses Set nodes between calls to prepare the data for the next agent. For example, it takes the output from the "Fetcher" agent and sets it as the input for the "Writer" agent.Workflow Steps:Trigger: Cron Node.Set Channel ID: Set Node to define the target YouTube Channel ID.Execute Agent 1 (YouTube Fetcher): Execute Workflow Node calls the "YouTube Fetcher & DB Storage" workflow, passing the Channel ID.Set Transcript Data: Set Node takes the transcript_id returned from Agent 1.Execute Agent 2 (Cantonese Writer): Execute Workflow Node calls the "Content Transformation" workflow, passing the transcript_id.Set Blog Data: Set Node takes the blog_post_id returned from Agent 2.Execute Agent 3 (Visual Extractor): Execute Workflow Node calls the "Visual Extractor" workflow, passing the blog_post_id.Execute Agent 4 (Designer): Execute Workflow Node calls the "Designer" workflow, passing the list of visual requirements.Execute Agent 5 (Formatter): Execute Workflow Node calls the "Formatter" workflow, passing the blog_post_id and the visual assets from Agent 4.Execute Agent 6 (Publisher): Execute Workflow Node calls the "Publisher" workflow, passing the Ghost-ready post data.End/Notify: A final PostgreSQL node to log the successful completion of the entire run, or a Discord/Slack node to send a notification.2. The Agent Workflows (Specialists)Each of these is a separate, self-contained workflow.Trigger: Webhook Node. The URL of this webhook is used by the Execute Workflow node in the Master Orchestrator.Function: Performs one specific job.Output: Returns a simple JSON object with the results (e.g., { "success": true, "transcript_id": 123 }).Agent 1: YouTube Fetcher & DB StorageTrigger: WebhookInput: { "channelId": "UC..." }Logic:YouTube Node (or HTTP Request to YouTube API) to find the latest video.YouTube Node to fetch the transcript.PostgreSQL Node to INSERT the transcript into a table.Returns: { "transcript_id": [ID from DB] }Agent 2: Cantonese WriterTrigger: WebhookInput: { "transcript_id": 123 }Logic:PostgreSQL Node to SELECT the transcript text.AI Agent / OpenAI Node to rewrite the text in Cantonese.PostgreSQL Node to INSERT the new blog text.Returns: { "blog_post_id": [ID from DB] }Agent 3: Visual ExtractorTrigger: WebhookInput: { "blog_post_id": 456 }Logic:PostgreSQL Node to SELECT the Cantonese blog text.AI Agent / OpenAI Node with a specific prompt to analyze text and return a JSON array of image requirements.Returns: { "visual_requirements": [{ "type": "search", "query": "..." }, { "type": "generate", "prompt": "..." }] }Agent 4: DesignerTrigger: WebhookInput: { "visual_requirements": [...] }Logic:Split in Batches Node to process one requirement at a time.IF Node to check type (search or generate).If search: Google Images / Pexels Node.If generate: OpenAI / Stability AI Node.Results are aggregated back into a list of URLs.Returns: { "visual_assets": ["url1.jpg", "url2.png"] }Agent 5: FormatterTrigger: WebhookInput: { "blog_post_id": 456, "visual_assets": [...] }Logic:PostgreSQL Node to get the blog text.Set Node to combine the text and image URLs into the specific HTML or JSON format required by the Ghost CMS API.Returns: { "ghost_post_data": { "title": "...", "html": "..." } }Agent 6: PublisherTrigger: WebhookInput: { "ghost_post_data": { ... } }Logic:Ghost Node to create a new post.PostgreSQL Node to log the publication URL and status.Returns: { "status": "published", "url": "..." }(The Monitor_Agent would be a separate workflow triggered by a different event, like a webhook from a web analytics platform, or a cron job that queries an analytics API.)